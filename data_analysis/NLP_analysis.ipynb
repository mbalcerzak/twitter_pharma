{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - Bag of Words approach\n",
    "\n",
    "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/malgo_000/Desktop/Web_scraping/twitter_scraping/tweet_texts_pharma/'\n",
    "#path = os.path.join(os.getcwd(), 'tweet_texts_pharma/')\n",
    "\n",
    "def prepare_dataset(company):\n",
    "    df = pd.read_csv(path + '%s_tweets.txt' % company, sep='|')\n",
    "    \n",
    "    df['company'] = company\n",
    "    df['id'] = df['id'].apply(str)\n",
    "    \n",
    "    df['hashtags'] = df['text'].apply(lambda s: re.findall(r'#(\\w+)', s))\n",
    "    df['num_hash'] = df['hashtags'].apply(len)\n",
    "    \n",
    "    df['tagged'] = df['text'].apply(lambda s: re.findall(r'@(\\w+)', s))\n",
    "    \n",
    "    def clean_tweet(tweet):\n",
    "        check = '(@[A-Za-z]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)'\n",
    "        return ' '.join(re.sub(check, ' ', tweet).split())\n",
    "        \n",
    "    df['clean_tweet'] = [clean_tweet(tweet) for tweet in df['text']] \n",
    "    df['len'] = df['clean_tweet'].apply(len)\n",
    "    df['text_as_list'] = df['clean_tweet'].apply(lambda x: x.lower()).str.split(' ')\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['created_at'])\n",
    "    df['date'] = df['datetime'].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "    df['hour'] = df['datetime'].apply(lambda x: x.hour)\n",
    "    df['month'] = df['datetime'].apply(lambda x: x.month)\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.day)\n",
    "    df['year'] = df['datetime'].apply(lambda x: x.year)\n",
    "    df = df.drop(columns=['created_at'])\n",
    "        \n",
    "    df['z'] = np.abs(stats.zscore(df['fav']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = prepare_dataset('AstraZeneca')\n",
    "\n",
    "def combine_tweets(company_names):\n",
    "    df_all = pd.DataFrame()\n",
    "    for company in company_names:\n",
    "        df_all = df_all.append(prepare_dataset(company), ignore_index = True)        \n",
    "    \n",
    "    df_all = df_all[df_all['z'] < 3] \n",
    "    df_all = df_all.append(df, ignore_index = True)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "company_list = ['JNJCares', 'Roche', 'Pfizer','Novartis', 'BayerPharma',\n",
    "                'Merck','GSK','Sanofi', 'abbvie', 'AbbottGlobal',\n",
    "                'LillyPad', 'Amgen', 'bmsnews', 'GileadSciences']\n",
    "\n",
    "df_all = combine_tweets(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   popular  \\\n",
      "0  0         \n",
      "1  0         \n",
      "2  0         \n",
      "3  1         \n",
      "4  0         \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                text_as_list  \n",
      "0  [thanks, for, sharing, please, send, us, a, direct, message, with, your, email, address, so, we, can, get, this, feedback, to, the, right, team]                                                                                                                                                           \n",
      "1  [thanks, for, reaching, out, our, team, that, supports, product, availability, in, the, uk, will, be, able, to, answer, your, question, best, you, can, contact, them, here, crc, jnj, com, have, a, great, day]                                                                                           \n",
      "2  [thank, you, for, taking, the, time, to, reach, out, to, us, and, share, your, feedback, we, ll, make, sure, to, pass, this, on, to, our, team]                                                                                                                                                            \n",
      "3  [dyk, j, amp, j, offers, transgender, inclusive, health, insurance, coverage, for, employees, in, honor, of, pridemonth, amp, our, commitment, to, a, diverse, workforce, discover, more, ways, we, support, lgbtq, employees, and, meet, a, jnj, ally, helping, lead, a, strong, culture, of, inclusion]  \n",
      "4  [to, get, the, best, answers, to, this, question, reach, out, to, our, team, near, you, they, can, be, contacted, by, phone, at, this, number, we, hope, you, have, a, great, day]                                                                                                                         \n"
     ]
    }
   ],
   "source": [
    "# counting company averages to tell which tweets were more popular\n",
    "df_all['percentile'] = df_all.groupby(['company'])['fav'].transform(lambda x: np.percentile(x,80))\n",
    "\n",
    "df_all['popular_tf'] = df_all['percentile'] <= df_all['fav']\n",
    "\n",
    "maping = {True: 1, False: 0}\n",
    "df_all['popular'] = df_all['popular_tf'].map(maping)\n",
    "\n",
    "df_analysis = df_all[['id','popular','text_as_list']]\n",
    "\n",
    "print(df_analysis[['popular','text_as_list']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pridemonth', 'lgbtq', 'jnj', '5bfilm', 'makehivhistory']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stopwords_english = stopwords.words('english')\n",
    " \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "hashtag_list = []\n",
    "for hashtag in df_all['hashtags']:\n",
    "        for h in hashtag:\n",
    "            if h.lower() not in hashtag_list:\n",
    "                hashtag_list.append(h.lower())\n",
    "                \n",
    "print(hashtag_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9955 38011\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()  \n",
    "\n",
    "# feature extractor function\n",
    "def bag_of_words(tweet):\n",
    "    words_dictionary = dict([lemmatizer.lemmatize(word), True] for word in tweet if word not in hashtag_list)    \n",
    "    return words_dictionary\n",
    " \n",
    "pop_tweets = df_analysis['text_as_list'][df_analysis['popular']==1]\n",
    "unpop_tweets = df_analysis['text_as_list'][df_analysis['popular']==0]\n",
    "\n",
    "# popular tweets feature set\n",
    "pop_tweets_set = []\n",
    "for tweet in pop_tweets:\n",
    "    pop_tweets_set.append((bag_of_words(tweet), 'pop'))    \n",
    " \n",
    " # less popular tweets feature set\n",
    "unpop_tweets_set = []\n",
    "for tweet in unpop_tweets:\n",
    "    unpop_tweets_set.append((bag_of_words(tweet), 'unpop'))\n",
    " \n",
    "print (len(pop_tweets_set), len(unpop_tweets_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 45966\n",
      "accuracy:  0.627\n",
      "Most Informative Features\n",
      "                      dm = True            unpop : pop    =    144.3 : 1.0\n",
      "                    send = True            unpop : pop    =    137.5 : 1.0\n",
      "                     com = True            unpop : pop    =    111.6 : 1.0\n",
      "                      hi = True            unpop : pop    =     91.4 : 1.0\n",
      "                     saw = True            unpop : pop    =     54.9 : 1.0\n",
      "                 contact = True            unpop : pop    =     51.7 : 1.0\n",
      "                  assist = True            unpop : pop    =     46.8 : 1.0\n",
      "                  please = True            unpop : pop    =     42.7 : 1.0\n",
      "                   ifato = True              pop : unpop  =     31.7 : 1.0\n",
      "                feedback = True            unpop : pop    =     29.9 : 1.0\n",
      "                    note = True            unpop : pop    =     24.7 : 1.0\n",
      "                stoffels = True              pop : unpop  =     23.4 : 1.0\n",
      "                 lillyrx = True            unpop : pop    =     20.1 : 1.0\n",
      "                 crystal = True            unpop : pop    =     19.7 : 1.0\n",
      "                 nearest = True            unpop : pop    =     19.6 : 1.0\n",
      "                   phone = True            unpop : pop    =     19.2 : 1.0\n",
      "                   elite = True              pop : unpop  =     17.9 : 1.0\n",
      "                   empty = True              pop : unpop  =     17.9 : 1.0\n",
      "                  lounge = True              pop : unpop  =     17.7 : 1.0\n",
      "                tireless = True              pop : unpop  =     15.2 : 1.0\n",
      "                    levy = True              pop : unpop  =     15.2 : 1.0\n",
      "               employing = True              pop : unpop  =     15.2 : 1.0\n",
      "               millionth = True              pop : unpop  =     15.2 : 1.0\n",
      "                flatiron = True              pop : unpop  =     15.2 : 1.0\n",
      "              inhibiting = True              pop : unpop  =     15.2 : 1.0\n",
      "                    bush = True              pop : unpop  =     15.2 : 1.0\n",
      "                 heavily = True            unpop : pop    =     15.1 : 1.0\n",
      "                 request = True            unpop : pop    =     14.9 : 1.0\n",
      "                  direct = True            unpop : pop    =     14.4 : 1.0\n",
      "                   touch = True            unpop : pop    =     14.2 : 1.0\n",
      "                  defect = True              pop : unpop  =     14.1 : 1.0\n",
      "                     lmb = True              pop : unpop  =     14.1 : 1.0\n",
      "              suggestion = True            unpop : pop    =     12.7 : 1.0\n",
      "                  muslim = True              pop : unpop  =     12.4 : 1.0\n",
      "                greeting = True              pop : unpop  =     12.4 : 1.0\n",
      "                   baker = True              pop : unpop  =     12.4 : 1.0\n",
      "                 justice = True              pop : unpop  =     12.4 : 1.0\n",
      "                   rated = True              pop : unpop  =     12.4 : 1.0\n",
      "                   jimmy = True              pop : unpop  =     12.4 : 1.0\n",
      "                    yale = True              pop : unpop  =     12.4 : 1.0\n",
      "                   manji = True              pop : unpop  =     12.4 : 1.0\n",
      "                  prince = True              pop : unpop  =     12.4 : 1.0\n",
      "                   stake = True              pop : unpop  =     12.4 : 1.0\n",
      "                   usatf = True              pop : unpop  =     12.4 : 1.0\n",
      "               legendary = True              pop : unpop  =     12.4 : 1.0\n",
      "              definitive = True              pop : unpop  =     12.4 : 1.0\n",
      "                 cassidy = True              pop : unpop  =     12.4 : 1.0\n",
      "                    goat = True              pop : unpop  =     12.4 : 1.0\n",
      "                reaching = True            unpop : pop    =     12.2 : 1.0\n",
      "                   hello = True            unpop : pop    =     12.2 : 1.0\n",
      "                      tc = True              pop : unpop  =     11.2 : 1.0\n",
      "                     cdo = True              pop : unpop  =     10.7 : 1.0\n",
      "               valentine = True              pop : unpop  =     10.7 : 1.0\n",
      "                  litman = True              pop : unpop  =     10.7 : 1.0\n",
      "                  oldest = True              pop : unpop  =     10.7 : 1.0\n",
      "           heartlinkgala = True              pop : unpop  =     10.7 : 1.0\n",
      "                  runner = True              pop : unpop  =     10.3 : 1.0\n",
      "                    cest = True            unpop : pop    =     10.2 : 1.0\n",
      "                rappuoli = True              pop : unpop  =     10.1 : 1.0\n",
      "                  gorsky = True              pop : unpop  =     10.0 : 1.0\n",
      "                 operate = True            unpop : pop    =      9.9 : 1.0\n",
      "                  parade = True              pop : unpop  =      9.6 : 1.0\n",
      "                   fluke = True              pop : unpop  =      9.6 : 1.0\n",
      "              transforms = True              pop : unpop  =      9.6 : 1.0\n",
      "                     imp = True              pop : unpop  =      9.6 : 1.0\n",
      "                shocking = True              pop : unpop  =      9.6 : 1.0\n",
      "              solidarity = True              pop : unpop  =      9.6 : 1.0\n",
      "          collaborateurs = True              pop : unpop  =      9.6 : 1.0\n",
      "           authorisation = True              pop : unpop  =      9.6 : 1.0\n",
      "                modality = True              pop : unpop  =      9.6 : 1.0\n",
      "                  merger = True              pop : unpop  =      9.6 : 1.0\n",
      "              competitor = True              pop : unpop  =      9.6 : 1.0\n",
      "                  heroic = True              pop : unpop  =      9.6 : 1.0\n",
      "                    pint = True              pop : unpop  =      9.6 : 1.0\n",
      "               festivity = True              pop : unpop  =      9.6 : 1.0\n",
      "                 mileage = True              pop : unpop  =      9.6 : 1.0\n",
      "                 touring = True              pop : unpop  =      9.6 : 1.0\n",
      "              fitzgerald = True              pop : unpop  =      9.6 : 1.0\n",
      "               underwent = True              pop : unpop  =      9.6 : 1.0\n",
      "                  meetup = True              pop : unpop  =      9.6 : 1.0\n",
      "                    lade = True              pop : unpop  =      9.6 : 1.0\n",
      "              powerhouse = True              pop : unpop  =      9.6 : 1.0\n",
      "                rosalind = True              pop : unpop  =      9.6 : 1.0\n",
      "                 dreamed = True              pop : unpop  =      9.6 : 1.0\n",
      "                 hawking = True              pop : unpop  =      9.6 : 1.0\n",
      "                  senate = True              pop : unpop  =      9.6 : 1.0\n",
      "                 someday = True              pop : unpop  =      9.6 : 1.0\n",
      "                   iaslc = True              pop : unpop  =      9.6 : 1.0\n",
      "                    acpa = True              pop : unpop  =      9.6 : 1.0\n",
      "                     azt = True              pop : unpop  =      9.6 : 1.0\n",
      "              assignment = True              pop : unpop  =      9.6 : 1.0\n",
      "                   rigor = True              pop : unpop  =      9.6 : 1.0\n",
      "                     tat = True              pop : unpop  =      9.6 : 1.0\n",
      "                 longest = True              pop : unpop  =      9.6 : 1.0\n",
      "                staffing = True              pop : unpop  =      9.6 : 1.0\n",
      "                  flight = True              pop : unpop  =      9.6 : 1.0\n",
      "                 faillat = True              pop : unpop  =      9.6 : 1.0\n",
      "               witnessed = True              pop : unpop  =      9.6 : 1.0\n",
      "                    loxo = True              pop : unpop  =      9.6 : 1.0\n",
      "                  datuna = True              pop : unpop  =      9.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle \n",
    "shuffle(pop_tweets_set)\n",
    "shuffle(unpop_tweets_set)\n",
    " \n",
    "test_set = pop_tweets_set[:1000] + unpop_tweets_set[:1000]\n",
    "train_set = pop_tweets_set[1000:] + unpop_tweets_set[1000:]\n",
    "\n",
    "print(len(test_set),  len(train_set))\n",
    "\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(\"accuracy: \", accuracy) # Output: 0.765\n",
    " \n",
    "print (classifier.show_most_informative_features(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of most liked hashtags\n",
    "\n",
    "df_hashtag = df_all[['hashtags', 'fav']][df_all['num_hash']>0]\n",
    "\n",
    "hashtag_dict = {}\n",
    "\n",
    "for row, f in zip(df_hashtag['hashtags'], df_hashtag['fav']):\n",
    "    for h in row:\n",
    "        if h in hashtag_dict: \n",
    "            hashtag_dict[h][0] += f\n",
    "            hashtag_dict[h][1] += 1\n",
    "        else:\n",
    "            hashtag_dict[h] = [f,1]\n",
    "            \n",
    "# Finding 10 highest values \n",
    "most_pop_hash = collections.Counter(hashtag_dict).most_common(10)  \n",
    " \n",
    "print(\"Hashtags that were the most popular overall:\") \n",
    "print(\" \")\n",
    "for k in most_pop_hash:    \n",
    "    print(k[0],\":\",k[1][0])     \n",
    "    \n",
    "fav_per_post = {}    \n",
    "    \n",
    "for j in hashtag_dict:\n",
    "    if hashtag_dict[j][0] != 0:\n",
    "        fav_per_post[j] = round(hashtag_dict[j][0]/hashtag_dict[j][1],2)\n",
    "\n",
    "# Finding 10 highest values \n",
    "most_eff_hash = collections.Counter(fav_per_post).most_common(10) \n",
    "print(\"------------------------------------------------------ \")\n",
    "print(\"Hashtags that received the most likes per use in total:\")     \n",
    "print(\" \")\n",
    "for k in most_eff_hash:    \n",
    "    print(k[0],\":\",int(k[1]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list_full =  sorted(df_all['company'].unique())\n",
    "\n",
    "daily_count_pd = pd.DataFrame(df_all['date'].unique(), columns = ['date_tweeted'])\n",
    "daily_count_pd = daily_count_pd.set_index('date_tweeted')\n",
    "\n",
    "for company in company_list_full:\n",
    "    dates = df_all['date'][df_all['company'] == company].value_counts()\n",
    "    dates = pd.DataFrame(dates, columns = ['date'])\n",
    "    dates.set_index('date')\n",
    "    daily_count_pd = pd.concat([daily_count_pd, dates], axis = 1, sort = True)\n",
    "    \n",
    "daily_count_pd.columns = company_list_full\n",
    "daily_count_pd = daily_count_pd.fillna(0)\n",
    "daily_count_pd.sort_index(ascending = 0)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
